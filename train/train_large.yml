#### general settings
name: train_gpt_asr_mass_hf2
use_tb_logger: true
gpu_ids: [0]
start_step: 0
fp16: false
checkpointing_enabled: true
wandb: true

datasets:
  train:
    name: clips
    n_workers: 4
    batch_size: 512
    mode: grand_conjoined_voice
    max_paired_audio_length: 780283
    max_solo_audio_length: 780283
    max_paired_text_length: 300
    max_solo_text_length: 350
    needs_collate: false
    paired_dataset_args:
      path: [/h/bigasr_dataset/mozcv/en/train.tsv,
      /h/bigasr_dataset/librispeech/train/train.txt,
      /h/bigasr_dataset/tedlium/train-all.txt,
      /h/bigasr_dataset/voxforge/train-all.txt,
      /h/bigasr_dataset/voxpopuli/audio/transcribed_data/en/asr_train.tsv,
      /h/bigasr_dataset/ljspeech/ljs_audio_text_train_filelist.txt]
      fetcher_mode: [mozilla_cv, libritts, libritts, libritts, voxpopuli, lj]
      use_bpe_tokenizer: true
    unsupervised_audio_args:
      path: [/h/bigasr_dataset/librispeech/train]
      cache_path: unused_cache_delete_me.pth
    text_corpus_args:
      corpi: [[bookcorpus, None]]
      cache_path: /h/huggingface_datasets/cache
  val:
    name: libritts
    n_workers: 1
    batch_size: 12
    mode: grand_conjoined_voice
    max_paired_audio_length: 780283
    max_solo_audio_length: 780283
    max_paired_text_length: 300
    max_solo_text_length: 350
    needs_collate: false
    only_paired: true
    paired_dataset_args:
      path: [/h/bigasr_dataset/librispeech/val/val.txt]
      fetcher_mode: [libritts]
      use_bpe_tokenizer: true

networks:
  gpt:
    type: generator
    which_model_G: gpt_asr_hf2
    kwargs:
      max_symbols_per_phrase: 500
      max_mel_frames: 3200
      layers: 20
      model_dim: 512
      heads: 8
      lean_encoder: true
      number_text_tokens: 256
      start_token: 255
      checkpointing: true

#### path
path:
  strict_load: true
  # Put your state in here to resume training
  #resume_state: ../experiments/train_gpt_asr_mass_hf2/training_state/0.state

steps:        
  generator:
    training: gpt

    optimizer: adamw
    optimizer_params:
      lr: !!float 3e-4
      weight_decay: !!float 1e-2
      beta1: 0.9
      beta2: 0.96
    clip_grad_eps: 4

    injectors:
      to_mel:
        type: torch_mel_spectrogram
        mel_norm_file: mel_norms.pth
        in: paired_audio
        out: padded_mel
      mel_aug:
        type: mel_mask
        train: true
        time_mask_count: 2
        in: padded_mel
        out: padded_mel
      fwd:
        type: generator
        generator: gpt
        in: [padded_mel, paired_audio_lengths, paired_text_tokens, paired_text_lengths]
        out: [loss_text, student_logits]
      fwd_text:
        type: generator
        generator: gpt
        method: text_only
        in: [text_tokens, paired_text_lengths]
        out: [loss_text_only]
    losses:
      text_ce:
        type: direct
        weight: 1
        key: loss_text
      text_only_ce:
        type: direct
        weight: 1
        key: loss_text_only

train:
  niter: 500000
  warmup_iter: -1
  mega_batch_factor: 4
  ema_rate: .999
  val_freq: 500

  default_lr_scheme: MultiStepLR
  gen_lr_steps: [ 20000, 40000, 60000 ]
  lr_gamma: 0.2
  warmup_steps: 1000

eval:
  pure: true

logger:
  print_freq: 10
  save_checkpoint_freq: 500
  visuals: []
  is_mel_spectrogram: true
  visual_debug_rate: 100